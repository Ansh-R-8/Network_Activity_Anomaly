{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m9B9rWh6eBz-"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, StackingClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "import time\n",
        "\n",
        "# Load the data\n",
        "train_data = pd.read_csv('Train_Data.csv')\n",
        "test_data = pd.read_csv('Test_Data.csv')\n",
        "\n",
        "columns_to_keep = [\n",
        "    'samesrvrate','srcbytes','dsthostsrvserrorrate','diffsrvrate','count','dstbytes','serrorrate','dsthostsamesrvrate',\n",
        " 'dsthostserrorrate','srvserrorrate','dsthostdiffsrvrate','dsthostsrvcount','dsthostsamesrcportrate','dsthostsrvrerrorrate','dsthostsrvdiffhostrate',\n",
        " 'dsthostrerrorrate','rerrorrate','srvdiffhostrate','dsthostcount','lastflag','srvrerrorrate','service','srvcount','flag',\n",
        " 'loggedin','duration','protocoltype','hot','land','isguestlogin'\n",
        "]\n",
        "\n",
        "# Preprocess the data\n",
        "X = train_data[columns_to_keep]\n",
        "y = train_data['attack']\n",
        "\n",
        "# Identify categorical and numerical columns\n",
        "categorical_cols = X.select_dtypes(include=['object']).columns\n",
        "numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns\n",
        "\n",
        "# Preprocessing pipelines for numerical and categorical features\n",
        "numerical_transformer = Pipeline(steps=[\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "# Combine preprocessing steps\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numerical_transformer, numerical_cols),\n",
        "        ('cat', categorical_transformer, categorical_cols)\n",
        "    ])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data for training and validation\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define classifiers\n",
        "estimators = [\n",
        "    ('xgb', XGBClassifier(use_label_encoder=False, eval_metric='logloss', n_estimators=100, max_depth=6, learning_rate=0.006)),\n",
        "    ('ada', AdaBoostClassifier(n_estimators=100, learning_rate=0.01))\n",
        "]\n",
        "# Stacking classifier with Logistic Regression as the final estimator\n",
        "stacking_clf = StackingClassifier(\n",
        "    estimators=estimators,\n",
        "    final_estimator=LogisticRegression(max_iter=1000)\n",
        ")\n",
        "\n",
        "# Define pipelines for stacking and bagging classifiers\n",
        "stacking_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                                    ('classifier', stacking_clf)])\n",
        "\n",
        "# Train stacking classifier\n",
        "start_time = time.time()\n",
        "stacking_pipeline.fit(X_train, y_train)\n",
        "training_time = time.time() - start_time\n",
        "\n",
        "# Predict on validation set\n",
        "y_pred_stacking = stacking_pipeline.predict(X_val)\n",
        "\n",
        "# Calculate F1 score for stacking classifier\n",
        "f1_stacking = f1_score(y_val, y_pred_stacking)\n",
        "\n",
        "print(f'Stacking Classifier Training Time: {training_time:.2f} seconds')\n",
        "print(f'Stacking Classifier F1 Score: {f1_stacking}')\n",
        "\n",
        "# Bagging classifier with Logistic Regression as base estimator\n",
        "bagging_clf = BaggingClassifier(\n",
        "    base_estimator=LogisticRegression(max_iter=1000),\n",
        "    n_estimators=10,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "bagging_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                                   ('classifier', bagging_clf)])\n",
        "\n",
        "# Train bagging classifier\n",
        "start_time = time.time()\n",
        "bagging_pipeline.fit(X_train, y_train)\n",
        "training_time = time.time() - start_time\n",
        "\n",
        "# Predict on validation set\n",
        "y_pred_bagging = bagging_pipeline.predict(X_val)\n",
        "\n",
        "# Calculate F1 score for bagging classifier\n",
        "f1_bagging = f1_score(y_val, y_pred_bagging)\n",
        "\n",
        "print(f'Bagging Classifier Training Time: {training_time:.2f} seconds')\n",
        "print(f'Bagging Classifier F1 Score: {f1_bagging}')\n",
        "\n",
        "# Determine the best model\n",
        "if f1_stacking > f1_bagging:\n",
        "    best_model = stacking_pipeline\n",
        "    print('Stacking Classifier is the best model')\n",
        "else:\n",
        "    best_model = bagging_pipeline\n",
        "    print('Bagging Classifier is the best model')\n",
        "\n",
        "# Predict on the test set with the best model\n",
        "test_preds = best_model.predict(test_data[columns_to_keep])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e_i3VypyexRM",
        "outputId": "efb9abe8-8f4a-4113-d1be-49dbc2b3cf28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stacking Classifier Training Time: 68.82 seconds\n",
            "Stacking Classifier F1 Score: 0.9989406779661018\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bagging Classifier Training Time: 9.49 seconds\n",
            "Bagging Classifier F1 Score: 0.9999243284146804\n",
            "Bagging Classifier is the best model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create submission file\n",
        "submission = pd.DataFrame({'attack': test_preds})\n",
        "submission.to_csv('submission.csv', index=False)"
      ],
      "metadata": {
        "id": "q9h9yHyohDDB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}